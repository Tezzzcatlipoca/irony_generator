raices[6]/raices[4]
raices[5]/raices[6]
72/12
5600*23
70/8
40000*13
library(ggplot2)
#Baja archivo de internet
UrlFileName<-"http://www.pronosticos.gob.mx/Documentos/Historicos/Melate.csv"
melate<-read.csv(UrlFileName)
?rm
rm(list=ls())
library(ggplot2)
#Baja archivo de internet
UrlFileName<-"http://www.pronosticos.gob.mx/Documentos/Historicos/Melate.csv"
melate<-read.csv(UrlFileName)
head(melate)
Ult<-melate[345:861,] #Escoge observaciones anteriores -TRAINING
Observ<-nrow(Ult)
Nums<-Ult[,3:9] #Escoge variables útiles
Observ<-nrow(Ult)
Nums<-Ult[,3:9] #Escoge variables útiles
dir()
setwd("Data Science")
setwd("R")
dir()
setwd("Irony")
dir()
path.expand()
getwd("")
getwd()
?read.table
# Buscar palabra en una serie de fuentes de información
# Abrir fuentes de información y colapsarlas en un solo objeto
train_text<-read.table("C:/Users/Tezzz/Documents/Data Science/R/Irony/Irony_generator.R",sep="\t", quote = "")
View(train_text)
# Buscar palabra en una serie de fuentes de información
# Abrir fuentes de información y colapsarlas en un solo objeto
train_text<-read.table("C:/Users/Tezzz/Documents/Data Science/R/Irony/text_input1.txt",sep="\t", quote = "")
train_text<-read.table("C:/Users/Tezzz/Documents/Data Science/R/Irony/Irony_generator.R",sep="\t", quote = "")
# Buscar palabra en una serie de fuentes de información
# Abrir fuentes de información y colapsarlas en un solo objeto
train_text<-read.table("C:/Users/Tezzz/Documents/Data Science/R/Irony/text_input1.txt",sep="\t", quote = "")
?grepl
# Obtener ubicaciones de palabra en cada texto.
ubi<-grepl(palabra,train_text,ignore.case = TRUE)
palabra<-"death"
# Obtener ubicaciones de palabra en cada texto.
ubi<-grepl(palabra,train_text,ignore.case = TRUE)
ubi<-regexpr(palabra,train_text,ignore.case = TRUE)
grepl("death","udeatha")
grepl("death","udeatoha")
grepl("death",c("udeatoha","death","a","aaadeathi","adada") )
# Obtener ubicaciones de palabra en cada texto.
ubi<-grepl(palabra,train_text[,1],ignore.case = TRUE)
sum(ubi)
head(train_text[,ubi])
head(which(ubi))
head(train_text[,which(ubi)])
head(train_text[which(ubi),])
head(train_text[which(ubi),],10)
install.packages(xlsx)
install.packages("xlsx")
install.packages("rJava")
library(rJava)
install.packages("randomForest")
install.packages("rgdal")
install.packages("rattle")
library(dplyr)
library(rpart)
install.packages("RColorBrewer")
install.packages("RGtk2")
library("rattle", lib.loc="~/R/win-library/3.4")
detach("package:rattle", unload=TRUE)
library("rattle", lib.loc="~/R/win-library/3.4")
remove.packages("rattle", lib="~/R/win-library/3.4")
install.packages("RGtk2")
install.packages("RGtk2")
install.packages("rattle")
library("rattle", lib.loc="~/R/win-library/3.4")
unlink('~/Trabajo/Nielsen/OSOBISTE/OC/OC in Mexico_word_cache', recursive = TRUE)
install.packages("e1071")
ubi
ubi2<-regexpr(palabra,train_text,ignore.case = TRUE)
head(ubi2)
ubi2<-regexpr(palabra,train_text[,1],ignore.case = TRUE)
head(ubi2)
head(ubi2,20)
head(ubi2[ubi2!=-1],20)
sum(ubi)
head(train_text[ubi])
head(train_text[,ubi])
head(train_text[ubi,])
?substr
head(substr(train_text[ubi,],ubi2,ubi2+5))
head(substr(train_text,ubi2,ubi2+5)[ubi,])
head(substr(train_text,ubi2,ubi2+5))
head(substr(train_text[ubi,],ubi2[ubi2!=-1],ubi2[ubi2!=-1]+5))
head(substr(train_text[ubi,],ubi2[ubi2!=-1],ubi2[ubi2!=-1]+5),20)
?paste0
contenidos<-paste0("site%3Aen.wikipedia.org",term,collapse = "+")
url<-paste0("https://www.google.com/search?q=", contenidos)# palabra1+palabra2
# Generador de Ironías BASADO EN WIKIPEDIA
term<-"coffee"
# Empleamos la biblioteca para leer códigos web
library('rvest')
contenidos<-paste0("site%3Aen.wikipedia.org",term,collapse = "+")
url<-paste0("https://www.google.com/search?q=", contenidos)# palabra1+palabra2
# Aquí se reciben varios resultados
webpage <- read_html(url)
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo <- html_nodes(webpage,'a')
url_titulo <- html_nodes(webpage,'.iUh30')
descr_titulo <- html_nodes(webpage,'div')
siguiente <- html_node(webpage,'span')
# Convertimos la información en texto
titulo_data <- html_text(titulo)
url_data <- html_text(url_titulo)
descr_data <- html_text(descr_titulo)
siguiente_data <- html_text(siguiente)
head(siguiente_data)
head(titulo_data)
head(titulo_data,20)
head(titulo_data,40)
head(titulo_data[grepl(titulo_data,"Wiki")],15)
View(titulo_data)
View(url_data)
head(descr_data)
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo <- html_nodes(webpage,'h3 a')
# Convertimos la información en texto
titulo_data <- html_text(titulo)
head(titulo_data)
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo <- html_nodes(webpage,'a h3')
# Convertimos la información en texto
titulo_data <- html_text(titulo)
head(titulo_data)
?html_node
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo <- html_nodes(webpage,'.rhs')
# Convertimos la información en texto
titulo_data <- html_text(titulo)
head(titulo_data)
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo <- html_nodes(webpage,'//h3[@class='r']//a')
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo <- html_nodes(webpage,"//h3[@class='r']//a")
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo_data<-webpage %>% html_nodes(“cite”) %>% html_text()
library(dplyr)
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo_data<- webpage %>% html_nodes(“cite”) %>% html_text()
# Aquí se reciben varios resultados
webpage <- read_html(url)
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo_data<- webpage %>% html_nodes(“cite”) %>% html_text()
library(urltools)
install.packages("urltools")
library(urltools)
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo_data<- webpage %>% html_nodes(“cite”) %>% html_text()
View(webpage)
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo_data<- webpage %>% html_nodes(“a”) %>% html_text()
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo_data<- webpage %>% html_nodes('a') %>% html_text()
titulo_data
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo_data<- webpage %>% html_nodes('cite') %>% html_text()
titulo_data
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo_data<- webpage %>% html_nodes('//*[@id="rso"]/div[1]/div/div/div/h3/a') %>% html_text()
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo_data<- webpage %>% html_nodes('/*[@id="rso"]/div[1]/div/div/div/h3/a') %>% html_text()
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo_data<- webpage %>% html_nodes('/*[@id="rso"]/div/div/div/div/h3/a') %>% html_text()
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo_data<- webpage %>% html_nodes('[@id="rso"]/div/div/div/div/h3/a') %>% html_text()
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo_data<- webpage %>% html_nodes('[id="rso"]/div/div/div/div/h3/a') %>% html_text()
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo_data<- webpage %>% html_nodes('[id="rso"] div div div div h3 a') %>% html_text()
titulo_data
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo_data<- webpage %>% html_nodes('[id="rso"]') %>% html_text()
titulo_data
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo_data<- webpage %>% html_nodes('#rso > div:nth-child(1) > div > div > div > h3 > a') %>% html_text()
titulo_data
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo_data<- webpage %>% html_nodes('a') %>% html_text()
titulo_data
?html_nodes
titulo_data<- webpage %>% html_nodes(xpath = "//*[@id="rso"]/div[3]/div/div[3]/div/div/h3/a") %>% html_text()
titulo_data<- webpage %>% html_nodes(xpath = "//[@id="rso"]/div[3]/div/div[3]/div/div/h3/a") %>% html_text()
titulo_data<- webpage %>% html_nodes(xpath = "//[id="rso"]/div[3]/div/div[3]/div/div/h3/a") %>% html_text()
titulo_data<- webpage %>% html_nodes(xpath = "//[@id='rso']/div[3]/div/div[3]/div/div/h3/a") %>% html_text()
titulo_data<- webpage %>% html_nodes(xpath = "//*[@id='rso']/div[3]/div/div[3]/div/div/h3/a") %>% html_text()
titulo_data
?html_attr
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
titulo_data<- webpage %>% html_nodes('.r') %>% html_text()
titulo_data
webpage %>% html_nodes('.r')
leer<-webpage %>% html_nodes('.r')
View(leer)
leer<-webpage %>% html_nodes('h3.r')
leer<-webpage %>% html_nodes('#res h3.r')
movie <- read_html("http://www.imdb.com/title/tt1490017/")
cast <- html_nodes(movie, "#titleCast span.itemprop")
View(cast)
html_text(cast)
html_name(cast)
html_attrs(cast)
html_attr(cast, "class")
ahora<-html_nodes(#rso h3.r a)
ahora<-html_nodes(webpage,"#rso h3.r a")
View(ahora)
html_text(ahora)
ahora<-html_nodes(webpage,"#rso h3.r")
html_text(ahora)
View(ahora)
otro<-html_nodes(xpath = "//*[@id="titleCast"]/table/tbody/tr[2]/td[2]/a/span")
otro<-html_nodes(xpath = '//*[@id="titleCast"]/table/tbody/tr[2]/td[2]/a/span')
otro<-html_nodes(cast,xpath = '//*[@id="titleCast"]/table/tbody/tr[2]/td[2]/a/span')
html_text(otro)
ahora<-html_nodes(webpage,"#rso .r h3 a")
html_text(ahora)
ahora<-html_nodes(webpage,"#rso .r h3")
html_text(ahora)
ahora<-html_nodes(webpage,".r")
html_text(ahora)
ahora<-html_nodes(webpage,"cite")
html_text(ahora)
ahora<-webpage %>% html_nodes("cite") html_text()
ahora<-webpage %>% html_nodes("cite") %>% html_text()
ahora
url1 = URLencode(paste0(“https://www.google.com/search?q=",name))
page1 <- read_html(url1)
results1 <- page1 %>% html_nodes(“cite”) %>% html_text()
result1 <- as.character(results1[1])
library(urltools)
url1 = URLencode(paste0(“https://www.google.com/search?q=",name))
page1 <- read_html(url1)
results1 <- page1 %>% html_nodes(“cite”) %>% html_text()
result1 <- as.character(results1[1])
name<-"Coffee"
url1 = URLencode(paste0(“https://www.google.com/search?q=",name))
page1 <- read_html(url1)
results1 <- page1 %>% html_nodes(“cite”) %>% html_text()
result1 <- as.character(results1[1])
URLencode(paste0(“https://www.google.com/search?q=",name))
Url1<-URLencode(paste0(https://www.google.com/search?q=",name"))
Url1<-URLencode(paste0("https://www.google.com/search?q=",name))
page1<-read_html(Url1)
results1<-page1 %>% html_nodes("cite") %>% html_text()
result1
results1
contenidos
url<-URLencode(paste0("https://www.google.com/search?q=", contenidos))# palabra1+palabra2
url
# Aquí se reciben varios resultados
webpage <- read_html(url)
View(webpage)
titulo_data<-webpage %>% html_nodes("cite") %>% html_text()
titulo_data
contenidos
contenidos<-paste0("site%3Aen.wikipedia.org",term,collapse = "+")
contenidos
?paste0
contenidos<-paste0("site%3Aen.wikipedia.org+",term)
contenidos
url<-URLencode(paste0("https://www.google.com/search?q=", contenidos))# palabra1+palabra2
# Aquí se reciben varios resultados
webpage <- read_html(url)
titulo_data<-webpage %>% html_nodes("cite") %>% html_text()
titulo_data
ahora<-html_nodes(webpage,"#rso .r h3")
html_text(ahora)
ahora<-html_nodes(webpage,"#rso h3.r")
html_text(ahora)
ahora<-html_nodes(webpage,"h3.r")
html_text(ahora)
term
siguiente<-html_nodes(webpage,"a.pn")
html_text(siguiente)
html_attr(siguiente,"href")
siguiente<-html_nodes(webpage,"#pnnext")
html_text(siguiente)
View(siguiente)
siguiente<-html_nodes(webpage,xpath = "//*[@id="pnnext"]/span[2]")
siguiente<-html_nodes(webpage,xpath = "//*[@id='pnnext']/span[2]")
html_text(siguiente)
siguiente<-html_nodes(webpage,xpath = "//*[@id='pnnext']")
html_text(siguiente)
siguiente<-html_nodes(webpage,"a.f1")
html_text(siguiente)
siguiente<-webpage %<% html_node("a.f1") %<% html_text()
siguiente<-webpage %>% html_node("a.f1") %>% html_text()
html_text(siguiente)
html_attrs(siguiente,"href")
?html_attr
html_attrs(siguiente)
html_attr(siguiente,"href")
siguiente<-webpage %>% html_node("#Page 2") %>% html_text()
siguiente
siguiente<-webpage %>% html_node("a.f1")
siguiente
siguiente<-webpage %>% html_node("#nav a.f1")
siguiente
siguiente<-webpage %>% html_node("a.pn")
siguiente
siguiente<-webpage %>% html_node("#pnnext a.pn")
siguiente
siguiente<-webpage %>% html_node("#pnnext span[2")
siguiente<-webpage %>% html_node("#pnnext span[2]")
siguiente<-webpage %>% html_node("#pnnext > span[2]")
siguiente<-webpage %>% html_node("#pnnext < span[2]")
siguiente<-webpage %>% html_node("#pnnext span a.pn")
siguiente
siguiente<-webpage %>% html_node("#pnnext span")
siguiente
siguiente<-webpage %>% html_node("#pnnext")
siguiente
siguiente<-webpage %>% html_node(xpath = "//*[@id='pnnext]/span[2]")
siguiente<-webpage %>% html_node(xpath = "//*[@id='pnnext']/span[2]")
siguiente
siguiente<-webpage %>% html_node(xpath = "//*[@id='pnnext']")
siguiente
siguiente<-webpage %>% html_node("a.pnnext")
siguiente
html_text(siguiente)
siguiente<-webpage %>% html_node("a.pnnext span[2]")
siguiente<-webpage %>% html_node("a.pnnext span")
html_text(siguiente)
siguiente
siguiente<-webpage %>% html_node("a.pnnext > span[2]")
siguiente<-webpage %>% html_node("a#pnnext.pn")
html_text(siguiente)
siguiente
siguiente<-webpage %>% html_node("#brs a")
html_text(siguiente)
siguiente
siguiente<-webpage %>% html_node("span.csb.ch")
html_text(siguiente)
siguiente
siguiente<-webpage %>% html_node('a:contains("Siguiente")') %>% html_text()
html_text(siguiente)
siguiente
siguiente<-webpage %>% html_node('a:contains("10")') %>% html_text()
html_text(siguiente)
siguiente
siguiente<-webpage %>% html_node('a:contains("starbucks")') %>% html_text()
html_text(siguiente)
siguiente
siguiente<-webpage %>% html_node('a:contains("giantpenis")') %>% html_text()
html_text(siguiente)
siguiente
siguiente<-webpage %>% html_node('a:contains("Siguiente")')
html_text(siguiente)
siguiente
html_attr(siguiente,"href")
class(html_attr(siguiente,"href"))
texto<-webpage %>% html_nodes("span.st") %>% html_text()
texto
# --------------------- Wikipedia --------------
url_wiki<-URLencode("https://en.wikipedia.org/wiki/Cortado")
wikipage<-read_html(url_wiki)
intro_texto<-wikipage %<% html_nodes("p.mw-content-text") %<% html_text()
intro_texto<-wikipage %>% html_nodes("p.mw-content-text") %>% html_text()
intro_texto
intro_texto<-wikipage %>% html_nodes("p.mw-content-text")
intro_texto
intro_texto<-wikipage %>% html_nodes("#mw-content-text")
intro_texto
html_text(intro_texto)
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
# Headers de cada resultado de búsqueda
titulo_data<- webpage %>% html_nodes('h3.r') %>% html_text()
# URLs de cada resultado de búsqueda
url_data <- webpage %>% html_nodes('cite') %>% html_text()
# Descripciones de cada resultado de búsqueda
descr_data<-webpage %>% html_nodes("span.st") %>% html_text()
# URL de la siguiente pantalla
siguiente<-webpage %>% html_node('a:contains("Siguiente")')
siguiente_data <- html_attr(siguiente,"href")
head(titulo_data)
head(url_data)
dim(titulo_data)
length(titulo_data)
length(url_data)
length(descr_data)
siguiente_data
length(titulo_data)>length(url_data)
grepl("^Im[.*]coffee$",titulo_data)
titulo_data
grepl("^Im{.*}coffee$",titulo_data)
grepl("^Im{.}coffee$",titulo_data)
grepl("^Im(.)coffee$",titulo_data)
grepl("^Im(.{*})coffee$",titulo_data)
grepl("^Im(.+)coffee$",titulo_data)
# Crear línea de expresión regular
linea<-paste0("^Im(.+)",term)
linea
# Crear línea de expresión regular
linea<-paste0("^Im(.+)",term,"$")
linea
?substr
gsub("+","\+","coffee+tv")
gsub("+","\\+","coffee+tv")
gsub("\+","\\+","coffee+tv")
gsub("\+","\\\+","coffee+tv")
gsub("\\+","\\\+","coffee+tv")
gsub("(\\+)","(\\)(\\+)","coffee+tv")
gsub("(\\+)","\\ \\+","coffee+tv")
gsub("(\\+)","\\\\+","coffee+tv")
gsub("(\\+)","\\\+","coffee+tv")
gsub("(\\+)","\\\\+","coffee+tv")
gsub("(\\+)","\\(\+)","coffee+tv")
gsub("(\\+)","\\ \+","coffee+tv")
gsub("(\\+)","\ \+","coffee+tv")
gsub("(\\+)","\\ \+","coffee+tv")
gsub("(\\+)","\ \\+","coffee+tv")
gsub("(\\+)","\\ \\+","coffee+tv")
gsub("(\\+)","(\\)\\+","coffee+tv")
gsub("(\\+)","(\\) \\+","coffee+tv")
gsub("\+","(\\) \\+","coffee+tv")
gsub("\\+","(\\) \\+","coffee+tv")
gsub("\\+","\\ \\+","coffee+tv")
gsub("\\+","\\\ \\+","coffee+tv")
gsub("\\+","\\\\\+","coffee+tv")
gsub("\\+","\\\\+","coffee+tv")
output<-gsub("\\+","\\\\+","coffee+tv")
output
prueba<-"Imágnes de wikipedia en otros+coffee+tv"
grepl(output,prueba)
prueba2<-"Imágnes de wikipedia en otros+coffee +tv"
grepl(output,prueba2)
gsub("\\+","\\\\+","coffee+tv")
gsub("\\+","\\\\+","coffee tv")
# Crear línea de expresión regular (corrigiendo los '+' por '\+')
terminos<-gsub("\\+","\\\\+",term)
linea<-paste0("^Im(.+)",terminos,"$")
cuales_coinc<-grepl(linea,titulo_data)
terminos
linea
cuales_coinc
cuales_coinc<-!grepl(linea,titulo_data)
cuales_coinc
titulos_trasq<-titulo_data[cuales_coinc]
titulo_data
titulos_trasq
# Crear cuadro
provisional<-data.frame(titulo=titulos_trasq,descr=descr_data,url=url_data)
View(provisional)
a<-data.frame()
b<-data.frame(a=1,b=0,c=1)
b
c<-rbind(a,b)
c
b<-data.frame(a=c(1,2,3),b=c(0,1,2),c=1)
b
siguiente_data
rm(list=ls())
# Generador de Ironías BASADO EN WIKIPEDIA
term<-"coffee"
# Empleamos la biblioteca para leer códigos web
library(rvest)
library(dplyr)
library(urltools)
contenidos<-paste0("site%3Aen.wikipedia.org+",term)
url<-URLencode(paste0("https://www.google.com/search?q=", contenidos))# palabra1+palabra2
# Aquí se reciben varios resultados
webpage <- read_html(url)
# Inicializar cuadro final
resultados<-data.frame()
for (ciclo in 1:10) {
# Empleamos el complemeto SelectorGadget de Chrome para identificar en código CSS que necesitamos. Identificamos su parte del código correspondiente.
# Headers de cada resultado de búsqueda
titulo_data<- webpage %>% html_nodes('h3.r') %>% html_text()
# URLs de cada resultado de búsqueda
url_data <- webpage %>% html_nodes('cite') %>% html_text()
# Descripciones de cada resultado de búsqueda
descr_data<-webpage %>% html_nodes("span.st") %>% html_text()
# URL de la siguiente pantalla
siguiente<-webpage %>% html_node('a:contains("Siguiente")')
siguiente_data <- html_attr(siguiente,"href")
# En algunos casos se muestran más títulos que resultados (Imágenes de wikipedia)
# Hay que eliminarlos
if(length(titulo_data)>length(url_data)){
# Crear línea de expresión regular (corrigiendo los '+' por '\+')
terminos<-gsub("\\+","\\\\+",term)
linea<-paste0("^Im(.+)",terminos,"$")
cuales_coinc<-!grepl(linea,titulo_data)
titulos_trasq<-titulo_data[cuales_coinc]
} else {
titulos_trasq<-titulo_data
}
# Crear cuadro
provisional<-data.frame(titulo=titulos_trasq,descr=descr_data,url=url_data,pantalla=ciclo)
# Concatenar resultados
resultados<-rbind(resultados,provisional)
# Traer nueva página
nuevo_url<-paste0("https://www.google.com",siguiente_data)
# Tiempo de espera para evitar bloqueos
Sys.sleep(3)
webpage <- read_html(nuevo_url)
}
View(resultados)
sum(grepl("Coffee",resultados$titulo))
100-74
